{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CascadeClassifier 0x7f922bddaf50>\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "print(face_cascade)\n",
    "def face_extract(img):\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped=img[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a database of 100 images per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extract(frame) is not None:\n",
    "        count+=1\n",
    "        \n",
    "        img= cv2.resize(face_extract(frame), (200,200))\n",
    "        #img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./Faces/Kashish/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path, img)\n",
    "        \n",
    "        cv2.putText(img, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    if count==100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "label=[]\n",
    "names=[ 'Kashish', 'Rakshit', 'Aditya']\n",
    "for name in names:\n",
    "    for i in range(1,100):       \n",
    "        photo=cv2.imread('./Faces/'+name+'/'+ str(i)+'.jpg')\n",
    "        train.append(np.asarray(photo))\n",
    "        label.append(name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'input':train, 'label':label})\n",
    "data['label']=label\n",
    "df = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(df['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 200, 200, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=[]\n",
    "for i in range(df.shape[0]):\n",
    "    z.append(df['input'][i])\n",
    "z=np.array(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= z[:230]\n",
    "X_train=X_train/255.0\n",
    "X_test=z[230:]\n",
    "X_test=X_test/255.0\n",
    "y_train= y[:230]\n",
    "y_test=y[230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 200, 200, 3)\n",
      "(67, 200, 200, 3)\n",
      "(230,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "names=['Kashish', 'Aditya', 'Rakshit']\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(names)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aditya' 'Rakshit' 'Kashish' 'Kashish' 'Aditya' 'Aditya' 'Rakshit'\n",
      " 'Kashish' 'Rakshit' 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Aditya'\n",
      " 'Aditya' 'Rakshit' 'Rakshit' 'Aditya' 'Aditya' 'Kashish' 'Kashish'\n",
      " 'Aditya' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Rakshit' 'Rakshit'\n",
      " 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Kashish' 'Kashish' 'Rakshit'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Aditya' 'Kashish' 'Kashish'\n",
      " 'Kashish' 'Kashish' 'Aditya' 'Rakshit' 'Aditya' 'Rakshit' 'Aditya'\n",
      " 'Aditya' 'Aditya' 'Aditya' 'Kashish' 'Kashish' 'Kashish' 'Aditya'\n",
      " 'Rakshit' 'Kashish' 'Kashish' 'Aditya' 'Rakshit' 'Aditya' 'Aditya'\n",
      " 'Aditya' 'Rakshit' 'Aditya' 'Kashish']\n"
     ]
    }
   ],
   "source": [
    "y_tr=label_encoder.transform(y_train)\n",
    "y_te=label_encoder.transform(y_test)\n",
    "#print(y_tr)\n",
    "#print(y_te)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y_tr)\n",
    "y_binary_tst=to_categorical(y_te)\n",
    "#print(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 99, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 97, 97, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                9437248   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,476,163\n",
      "Trainable params: 9,476,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 161 samples, validate on 69 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 1.3045 - acc: 0.3354 - val_loss: 1.0882 - val_acc: 0.3478\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 1.0353 - acc: 0.3416 - val_loss: 1.2244 - val_acc: 0.3333\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.7550 - acc: 0.5652 - val_loss: 0.4587 - val_acc: 0.8406\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 10s 64ms/step - loss: 0.3935 - acc: 0.7640 - val_loss: 0.2374 - val_acc: 0.8696\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 10s 65ms/step - loss: 0.0905 - acc: 0.9752 - val_loss: 0.0192 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe459e50ef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "name='cnn-{}'.format(int(time.time()))\n",
    "model.add(Conv2D(64, (3,3), input_shape=(200,200,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_binary, batch_size=32, epochs=5, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 16ms/step\n",
      "validation accuracy is-100.0 %\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc=cnn_model.evaluate(X_test, y_binary_tst)\n",
    "print('validation accuracy is-{} %'.format(val_acc* 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7431ce6b6286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Face Recognition CNN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('Face Recognition CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 10:19:33.526835 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0701 10:19:33.571637 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0701 10:19:33.595315 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0701 10:19:33.711334 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0701 10:19:33.711974 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0701 10:19:33.712537 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0701 10:19:33.902168 140266748008256 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0701 10:19:33.998052 140266748008256 deprecation.py:323] From /home/home/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cnn_model= keras.models.load_model('Face Recognition CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    ans=[]\n",
    "    result=[]\n",
    "\n",
    "    prediction=cnn_model.predict(x)\n",
    "    prediction.shape\n",
    "    \n",
    "    for i in range(prediction.shape[0]):\n",
    "        ans.append(np.argmax(prediction[i]))\n",
    "        result=label_encoder.inverse_transform(ans)\n",
    "    #print(ans)    \n",
    "    #print(result)\n",
    "    print(type(result))\n",
    "    #print(result[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "['Aditya' 'Rakshit' 'Kashish' 'Kashish' 'Aditya' 'Aditya' 'Rakshit'\n",
      " 'Kashish' 'Rakshit' 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Aditya'\n",
      " 'Aditya' 'Rakshit' 'Rakshit' 'Aditya' 'Aditya' 'Kashish' 'Kashish'\n",
      " 'Aditya' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Rakshit' 'Rakshit'\n",
      " 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Kashish' 'Kashish' 'Rakshit'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Aditya' 'Kashish' 'Kashish'\n",
      " 'Kashish' 'Kashish' 'Aditya' 'Rakshit' 'Aditya' 'Rakshit' 'Aditya'\n",
      " 'Aditya' 'Aditya' 'Aditya' 'Kashish' 'Kashish' 'Kashish' 'Aditya'\n",
      " 'Rakshit' 'Kashish' 'Kashish' 'Aditya' 'Rakshit' 'Aditya' 'Aditya'\n",
      " 'Aditya' 'Rakshit' 'Aditya' 'Kashish']\n"
     ]
    }
   ],
   "source": [
    "print(predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Test/1.jpg\n",
      "./Test/2.jpg\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extract(frame) is not None:\n",
    "        count+=1\n",
    "        \n",
    "        img= cv2.resize(face_extract(frame), (200,200))\n",
    "        #img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./Test/'+str(count)+'.jpg'\n",
    "        print(file_name_path)\n",
    "        cv2.imwrite(file_name_path, img)\n",
    "        \n",
    "        cv2.putText(img, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    if count==2:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Aditya\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo= cv2.imread('./Test/2.jpg')\n",
    "test=[]\n",
    "test.append(np.asarray(photo))\n",
    "test=np.array(test)\n",
    "ans=predict(test)\n",
    "print(ans[0])\n",
    "type(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5d4db5da249a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_COMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    cv2.putText(photo,ans[0],(50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0),2  )\n",
    "    cv2.imshow('test', photo)\n",
    "    if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5e8d0d5b30ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mface_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extract(frame) is not None:\n",
    "        count+=1\n",
    "        \n",
    "        img= cv2.resize(face_extract(frame), (200,200))\n",
    "        #img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./Test/'+str(count)+'.jpg'\n",
    "        print(file_name_path)\n",
    "        cv2.imwrite(file_name_path, img)\n",
    "        \n",
    "        photo= cv2.imread(file_name_path)\n",
    "        test=[]\n",
    "        test.append(np.asarray(photo))\n",
    "        test=np.array(test)\n",
    "        ans=predict(test)\n",
    "        \n",
    "        cv2.putText(photo, ans[0], (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    if count==5:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers=[0,1,2]\n",
    "layer_sizes= [32, 64, 128]\n",
    "conv_layers=[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name= \"{}- conv-{}-nodes- {}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(\"********************* \"+name+\" ************************\")  \n",
    "            \n",
    "            model=Sequential()\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X_train.shape[1:], activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for i in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "            for i in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "            \n",
    "            model.add(Dense(3, activation='softmax')) \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "            model.fit(X_train, y_binary, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
