{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CascadeClassifier 0x7f3c9427e330>\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "print(face_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def face_extract(img):\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped=img[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extract(frame) is not None:\n",
    "        count+=1\n",
    "        \n",
    "        img= cv2.resize(face_extract(frame), (200,200))\n",
    "        #img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./Faces/Kashish/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path, img)\n",
    "        \n",
    "        cv2.putText(img, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    if count==1000:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "label=[]\n",
    "names=[ 'Kashish', 'Rakshit', 'Aditya']\n",
    "for name in names:\n",
    "    for i in range(1,100):       \n",
    "        photo=cv2.imread('./Faces/'+name+'/'+ str(i)+'.jpg')\n",
    "        train.append(np.asarray(photo))\n",
    "        label.append(name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'input':train, 'label':label})\n",
    "data['label']=label\n",
    "df = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(df['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 200, 200, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=[]\n",
    "for i in range(df.shape[0]):\n",
    "    z.append(df['input'][i])\n",
    "z=np.array(z)\n",
    "z.shape\n",
    "#z.reshape(267,200,200)\n",
    "#print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= z[:230]\n",
    "X_train=X_train/255\n",
    "X_test=z[230:]\n",
    "X_test=X_test/255\n",
    "y_train= y[:230]\n",
    "y_test=y[230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 200, 200, 3)\n",
      "(67, 200, 200, 3)\n",
      "(230,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Kashish', 'Aditya', 'Rakshit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(names)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 2 0 2 2 0 1 1 2 1 1 1 1 1 0 2 0 0 2 2 0 2 0 0 1 1 2 1 2 0 1 1 2\n",
      " 2 1 1 0 1 1 0 0 2 1 0 0 2 1 2 2 0 2 0 2 0 2 2 0 0 2 2 2 0 2 0 1 1 0 2 0 2\n",
      " 0 1 1 2 0 2 0 2 1 1 2 0 0 0 1 1 0 0 2 2 0 1 1 1 1 2 0 0 1 0 0 1 0 2 2 0 2\n",
      " 0 2 0 1 0 2 0 1 2 1 0 2 2 1 2 0 0 0 0 1 2 0 0 2 2 1 2 1 0 2 1 2 2 0 1 0 2\n",
      " 0 1 1 1 0 0 0 1 2 2 1 1 2 0 1 2 0 1 0 2 0 1 2 2 0 2 1 1 1 0 2 2 1 1 1 2 0\n",
      " 1 2 1 2 0 2 0 0 1 2 0 1 0 0 0 1 1 0 1 0 0 1 1 1 2 2 2 1 1 0 0 2 0 0 2 1 2\n",
      " 0 2 0 2 2 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "y_tr=label_encoder.transform(y_train)\n",
    "y_te=label_encoder.transform(y_test)\n",
    "print(y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y_tr)\n",
    "#print(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 161 samples, validate on 69 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 1.5354 - acc: 0.3665 - val_loss: 1.0648 - val_acc: 0.3188\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 10s 65ms/step - loss: 0.8918 - acc: 0.3913 - val_loss: 1.2836 - val_acc: 0.6812\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 11s 65ms/step - loss: 0.6240 - acc: 0.7329 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 10s 65ms/step - loss: 0.0610 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 0.9420\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 11s 67ms/step - loss: 0.0595 - acc: 0.9689 - val_loss: 0.0034 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bae21cfd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "name='cnn-{}'.format(int(time.time()))\n",
    "model.add(Conv2D(64, (3,3), input_shape=(200,200,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_binary, batch_size=32, epochs=5, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.15036964e-05 1.00000000e+00 1.00000000e+00]\n",
      " [7.80820847e-06 1.00000000e+00 1.00000000e+00]\n",
      " [1.54376030e-05 1.00000000e+00 1.00000000e+00]\n",
      " [4.76837158e-07 1.00000000e+00 9.99999881e-01]\n",
      " [7.33137131e-06 1.00000000e+00 1.00000000e+00]\n",
      " [9.77516174e-06 1.00000000e+00 1.00000000e+00]\n",
      " [4.47034836e-07 1.00000000e+00 9.99999940e-01]\n",
      " [1.31130219e-06 1.00000000e+00 9.99999881e-01]\n",
      " [1.42753124e-05 1.00000000e+00 1.00000000e+00]\n",
      " [2.93850899e-05 1.00000000e+00 9.99997318e-01]\n",
      " [1.29938126e-05 1.00000000e+00 1.00000000e+00]\n",
      " [9.97337699e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.98436689e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.97268558e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.98427033e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.89437103e-06 1.00000000e+00 1.00000000e+00]\n",
      " [9.94251668e-01 1.00000000e+00 1.00000000e+00]\n",
      " [1.90734863e-06 1.00000000e+00 1.00000000e+00]\n",
      " [1.43051147e-06 1.00000000e+00 9.99999762e-01]\n",
      " [7.45058060e-07 1.00000000e+00 9.99999881e-01]\n",
      " [4.14252281e-06 1.00000000e+00 1.00000000e+00]\n",
      " [7.06315041e-06 1.00000000e+00 1.00000000e+00]\n",
      " [6.64591789e-06 1.00000000e+00 9.99999881e-01]\n",
      " [2.43186951e-05 1.00000000e+00 9.99999762e-01]\n",
      " [1.50203705e-05 1.00000000e+00 1.00000000e+00]\n",
      " [1.14738941e-05 1.00000000e+00 9.99999523e-01]\n",
      " [6.31213188e-05 1.00000000e+00 1.00000000e+00]\n",
      " [3.30507755e-05 1.00000000e+00 1.00000000e+00]\n",
      " [6.02006912e-06 1.00000000e+00 1.00000000e+00]\n",
      " [4.17232513e-07 1.00000000e+00 9.99999881e-01]\n",
      " [9.96862650e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.96021092e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.95768905e-01 1.00000000e+00 1.00000000e+00]\n",
      " [1.40666962e-05 1.00000000e+00 1.00000000e+00]\n",
      " [1.77919865e-05 1.00000000e+00 1.00000000e+00]\n",
      " [1.46031380e-06 1.00000000e+00 1.00000000e+00]\n",
      " [7.74860382e-07 1.00000000e+00 1.00000000e+00]\n",
      " [9.95590806e-01 1.00000000e+00 1.00000000e+00]\n",
      " [1.85668468e-04 1.00000000e+00 1.00000000e+00]\n",
      " [1.82688236e-05 1.00000000e+00 1.00000000e+00]\n",
      " [7.30156898e-06 1.00000000e+00 1.00000000e+00]\n",
      " [7.59959221e-06 1.00000000e+00 1.00000000e+00]\n",
      " [9.98521328e-01 1.00000000e+00 1.00000000e+00]\n",
      " [3.09050083e-05 1.00000000e+00 1.00000000e+00]\n",
      " [6.88433647e-06 1.00000000e+00 1.00000000e+00]\n",
      " [9.95397568e-06 1.00000000e+00 1.00000000e+00]\n",
      " [5.66244125e-07 1.00000000e+00 9.99999881e-01]\n",
      " [1.65700912e-05 1.00000000e+00 1.00000000e+00]\n",
      " [4.17232513e-07 1.00000000e+00 9.99999881e-01]\n",
      " [4.12464142e-05 1.00000000e+00 9.99998391e-01]\n",
      " [2.53319740e-06 1.00000000e+00 9.99999881e-01]\n",
      " [4.56869602e-05 1.00000000e+00 1.00000000e+00]\n",
      " [9.96358097e-01 1.00000000e+00 1.00000000e+00]\n",
      " [2.83122063e-05 1.00000000e+00 1.00000000e+00]\n",
      " [5.39422035e-06 1.00000000e+00 9.99999881e-01]\n",
      " [9.92577732e-01 1.00000000e+00 1.00000000e+00]\n",
      " [2.68220901e-07 1.00000000e+00 9.99999881e-01]\n",
      " [8.58306885e-06 1.00000000e+00 1.00000000e+00]\n",
      " [1.15036964e-05 1.00000000e+00 9.99999344e-01]\n",
      " [1.23679638e-05 1.00000000e+00 1.00000000e+00]\n",
      " [9.96991396e-01 1.00000000e+00 1.00000000e+00]\n",
      " [9.97618079e-01 1.00000000e+00 1.00000000e+00]\n",
      " [5.48362732e-06 1.00000000e+00 9.99999583e-01]\n",
      " [2.52723694e-05 1.00000000e+00 1.00000000e+00]\n",
      " [9.98176694e-01 1.00000000e+00 1.00000000e+00]\n",
      " [6.52670860e-06 1.00000000e+00 1.00000000e+00]\n",
      " [9.95122075e-01 1.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(accuracy_score(ans, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-8064839cafde>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-8064839cafde>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    */\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "dense_layers=[0,1,2]\n",
    "layer_sizes= [32, 64, 128]\n",
    "conv_layers=[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name= \"{}- conv-{}-nodes- {}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(\"********************* \"+name+\" ************************\")  \n",
    "            \n",
    "            model=Sequential()\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X_train.shape[1:], activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for i in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "            for i in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "            \n",
    "            model.add(Dense(3, activation='softmax')) \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "            model.fit(X_train, y_binary, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 97, 97, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                9437248   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,476,163\n",
      "Trainable params: 9,476,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
