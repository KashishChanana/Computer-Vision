{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CascadeClassifier 0x7f2a25c8d2f0>\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "print(face_cascade)\n",
    "def face_extract(img):\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped=img[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a database of 100 images per person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "count=0\n",
    "while(True):\n",
    "    ret, frame=cap.read()\n",
    "    if face_extract(frame) is not None:\n",
    "        count+=1\n",
    "        \n",
    "        img= cv2.resize(face_extract(frame), (200,200))\n",
    "        #img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        file_name_path='./Faces/Kashish/'+str(count)+'.jpg'\n",
    "        cv2.imwrite(file_name_path, img)\n",
    "        \n",
    "        cv2.putText(img, str(count), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,0),2)\n",
    "        cv2.imshow('image',img)\n",
    "        if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    if count==100:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "label=[]\n",
    "names=[ 'Kashish', 'Rakshit', 'Aditya']\n",
    "for name in names:\n",
    "    for i in range(1,100):       \n",
    "        photo=cv2.imread('./Faces/'+name+'/'+ str(i)+'.jpg')\n",
    "        train.append(np.asarray(photo))\n",
    "        label.append(name)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({'input':train, 'label':label})\n",
    "data['label']=label\n",
    "df = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.array(df['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297, 200, 200, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=[]\n",
    "for i in range(df.shape[0]):\n",
    "    z.append(df['input'][i])\n",
    "z=np.array(z)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= z[:230]\n",
    "X_train=X_train/255.0\n",
    "X_test=z[230:]\n",
    "X_test=X_test/255.0\n",
    "y_train= y[:230]\n",
    "y_test=y[230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(230, 200, 200, 3)\n",
      "(67, 200, 200, 3)\n",
      "(230,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "names=['Kashish', 'Aditya', 'Rakshit']\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(names)\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kashish' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Aditya'\n",
      " 'Aditya' 'Kashish' 'Aditya' 'Aditya' 'Aditya' 'Rakshit' 'Rakshit'\n",
      " 'Aditya' 'Aditya' 'Aditya' 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit'\n",
      " 'Aditya' 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Kashish'\n",
      " 'Kashish' 'Aditya' 'Kashish' 'Aditya' 'Aditya' 'Kashish' 'Aditya'\n",
      " 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit' 'Rakshit' 'Aditya' 'Kashish'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Rakshit' 'Rakshit' 'Rakshit' 'Aditya'\n",
      " 'Kashish' 'Rakshit' 'Kashish' 'Rakshit' 'Aditya' 'Aditya' 'Aditya'\n",
      " 'Aditya' 'Kashish' 'Aditya' 'Rakshit']\n"
     ]
    }
   ],
   "source": [
    "y_tr=label_encoder.transform(y_train)\n",
    "y_te=label_encoder.transform(y_test)\n",
    "#print(y_tr)\n",
    "#print(y_te)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y_tr)\n",
    "y_binary_tst=to_categorical(y_te)\n",
    "#print(y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 99, 99, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 97, 97, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 147456)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                9437248   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,476,163\n",
      "Trainable params: 9,476,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 161 samples, validate on 69 samples\n",
      "Epoch 1/5\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 1.4717 - acc: 0.3043 - val_loss: 1.0066 - val_acc: 0.3623\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 12s 73ms/step - loss: 0.9319 - acc: 0.4534 - val_loss: 0.8301 - val_acc: 0.6667\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 11s 66ms/step - loss: 0.7669 - acc: 0.5155 - val_loss: 0.3983 - val_acc: 0.6667\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 10s 64ms/step - loss: 0.2195 - acc: 0.9130 - val_loss: 0.0494 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 11s 69ms/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ad421d438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "name='cnn-{}'.format(int(time.time()))\n",
    "model.add(Conv2D(64, (3,3), input_shape=(200,200,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_binary, batch_size=32, epochs=5, validation_split=0.3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 1s 14ms/step\n",
      "0.0014116546319825436 1.0\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc=model.evaluate(X_test, y_binary_tst)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Face Recognition CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0629 11:42:36.266363 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0629 11:42:36.292382 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0629 11:42:36.316991 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0629 11:42:36.424427 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0629 11:42:36.425079 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0629 11:42:36.425708 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0629 11:42:36.587511 139819972069184 deprecation_wrapper.py:119] From /home/home/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0629 11:42:36.687697 139819972069184 deprecation.py:323] From /home/home/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "cnn_model= keras.models.load_model('Face Recognition CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    ans=[]\n",
    "    result=[]\n",
    "\n",
    "    prediction=cnn_model.predict(x)\n",
    "    prediction.shape\n",
    "    \n",
    "    for i in range(prediction.shape[0]):\n",
    "        ans.append(np.argmax(prediction[i]))\n",
    "        result=label_encoder.inverse_transform(ans)\n",
    "    #print(ans)    \n",
    "    #print(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kashish' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Aditya'\n",
      " 'Aditya' 'Kashish' 'Aditya' 'Aditya' 'Aditya' 'Rakshit' 'Rakshit'\n",
      " 'Aditya' 'Aditya' 'Aditya' 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit'\n",
      " 'Aditya' 'Rakshit' 'Aditya' 'Rakshit' 'Kashish' 'Aditya' 'Kashish'\n",
      " 'Kashish' 'Aditya' 'Kashish' 'Aditya' 'Aditya' 'Kashish' 'Aditya'\n",
      " 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit' 'Rakshit' 'Aditya' 'Kashish'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Kashish' 'Rakshit' 'Rakshit' 'Rakshit'\n",
      " 'Rakshit' 'Kashish' 'Aditya' 'Rakshit' 'Rakshit' 'Rakshit' 'Aditya'\n",
      " 'Kashish' 'Rakshit' 'Kashish' 'Rakshit' 'Aditya' 'Aditya' 'Aditya'\n",
      " 'Aditya' 'Kashish' 'Aditya' 'Rakshit']\n"
     ]
    }
   ],
   "source": [
    "print(predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5f2ab3eacc8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mface_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_COMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'check'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cfc2847678bb>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     78\u001b[0m                              'for each key in: ' + str(names))\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def face_extract(img):\n",
    "    gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "        cropped=img[y:y+h, x:x+w]\n",
    "        resized=cv2.resize(cropped, (200,200))\n",
    "    return img,resized\n",
    "    \n",
    "    \n",
    "cap=cv2.VideoCapture(0)\n",
    "cnt=0\n",
    "while(cnt<2):\n",
    "    ret, frame=cap.read()\n",
    "    \n",
    "    img,face=face_extract(frame)\n",
    "    result=predict(face)\n",
    "    cv2.putText(img,result[0],(100,100), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0),2 )\n",
    "    cv2.imshow('check', img)\n",
    "    \n",
    "    #print(face.shape)\n",
    "    \n",
    "    \n",
    "    cnt+=1\n",
    "    \n",
    "    \n",
    "   # try:\n",
    "        #result=predict(face)\n",
    "        #if result[1]<500:\n",
    "         #   confidence_value = int(100* (1-(result[1]/300)))\n",
    "        #if confidence_value>80:\n",
    "         #   cv2.putText(img,\"Confidence \"+str(confidence_value),(100,100), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0),2 )\n",
    "          #  cv2.imshow('check', img)\n",
    "    #except:\n",
    "        #cv2.putText(img,\"NO FACE\", (100,100),cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0),2 )\n",
    "        #cv2.imshow('check', img)\n",
    "        #pass\n",
    "    if cv2.waitKey(13)& 0xFF == ord('q'):\n",
    "        break\n",
    "    if cnt==2:\n",
    "        break\n",
    "        \n",
    "    \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers=[0,1,2]\n",
    "layer_sizes= [32, 64, 128]\n",
    "conv_layers=[1,2,3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name= \"{}- conv-{}-nodes- {}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(\"********************* \"+name+\" ************************\")  \n",
    "            \n",
    "            model=Sequential()\n",
    "            model.add(Conv2D(layer_size, (3,3), input_shape=X_train.shape[1:], activation='relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "            \n",
    "            for i in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3,3), activation='relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "                \n",
    "            model.add(Flatten())\n",
    "            for i in range(dense_layer):\n",
    "                model.add(Dense(layer_size, activation='relu'))\n",
    "            \n",
    "            model.add(Dense(3, activation='softmax')) \n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(name))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "            model.fit(X_train, y_binary, batch_size=32, epochs=10, validation_split=0.3, callbacks=[tensorboard])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
